{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the MCV, one may fit the model to many splits of the data. How dependent is the ss-loss to the split? How dependent is the gt loss?\n",
    "\n",
    "One may also average together the outputs resulting from denoising with many splits. The (relative) quality of the resulting denoiser should be given by subtracting from the average ss-loss the variance of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import os\n",
    "from util import normalize_rows, mse, expected_sqrt, expected_log1p, poisson_log_lik\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_to = 3000\n",
    "min_counts_per_gene = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Users/josh/src/noise2self-single-cell/data/neurons/neurons_deep.h5ad'\n",
    "data = sc.read(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(data, min_counts=min_counts_per_gene)\n",
    "data_down = sc.pp.downsample_counts(data, downsample_to, replace = False, copy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data_down.X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.binomial(x, 0.5)\n",
    "x2 = x - x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data.X.todense())\n",
    "mean = y/y.sum(axis = 1, keepdims = True) * downsample_to/2\n",
    "z = expected_sqrt(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_sqrt_half_means = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_opt = 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each split $X = X_1, X_2$, we compute PCA on $X_1$ and record the quality of the resulting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing  0\n",
      "Computing  1\n",
      "Computing  2\n",
      "Computing  3\n",
      "Computing  4\n",
      "Computing  5\n",
      "Computing  6\n",
      "Computing  7\n",
      "Computing  8\n",
      "Computing  9\n",
      "Computing  10\n",
      "Computing  11\n"
     ]
    }
   ],
   "source": [
    "n_splits = 12\n",
    "ss_losses = []\n",
    "gt_losses = []\n",
    "\n",
    "accumulator = np.zeros(x.shape)\n",
    "accumulator_sq = np.zeros(x.shape)\n",
    "for i in np.arange(n_splits):\n",
    "    print(\"Computing \", i)\n",
    "    np.random.seed(i)\n",
    "    x1 = np.random.binomial(x, 0.5)\n",
    "    x2 = x - x1\n",
    "    U, S, V = randomized_svd(np.sqrt(x1), 50)\n",
    "    denoised = np.sqrt(x1).dot(V[:k_opt,:].T).dot(V[:k_opt,:])\n",
    "    accumulator += denoised\n",
    "    accumulator_sq += denoised**2\n",
    "    ss_losses.append(mse(denoised, x2))\n",
    "    gt_losses.append(mse(denoised, z))\n",
    "average = accumulator/n_splits\n",
    "var = accumulator_sq/n_splits - average**2\n",
    "gt_loss = mse(average, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gain is due to variance of denoised outputs\n",
    "np.allclose(var.mean() + gt_loss, np.mean(gt_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS Losses\n",
      "[0.73, 0.732, 0.733, 0.733, 0.734, 0.736, 0.736, 0.736, 0.736, 0.737, 0.737, 0.738]\n",
      "GT Losses\n",
      "[0.0055, 0.00551, 0.00551, 0.00551, 0.00551, 0.00551, 0.00551, 0.00551, 0.00551, 0.00552, 0.00552, 0.00552]\n",
      "Accumulator GT Loss\n",
      "0.00511\n",
      "Gain from averaging\n",
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "print(\"SS Losses\")\n",
    "print([np.round(x, 3) for x in sorted(ss_losses)])\n",
    "print(\"GT Losses\")\n",
    "print([np.round(x, 5) for x in sorted(gt_losses)])\n",
    "print(\"Accumulator GT Loss\")\n",
    "print(np.round(gt_loss, 5))\n",
    "print(\"Gain from averaging\")\n",
    "print(np.round(var.mean(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the denoisers from each split have very similar ground-truth performance (differing in the third significant digit). More variance is present in the self-supervised loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
